{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processor\n",
    "\n",
    "This file is used to format, generate, filter, and split our data.\n",
    "\n",
    "The raw data is a CSV file represented as a list of tuples \n",
    "containing x and y co-ordinates for each \"stroke/drag\" across \n",
    "the screen. It also contained added meta data that will be \n",
    "filtered out leaving only the data and its label.\n",
    "e.g. [[[x1, ...], [y1, ...]], ...]\n",
    "\n",
    "1. Formating Data to Images\n",
    "The first step is to convert the data into images.\n",
    "While images are more data intensive for rempresting the data,\n",
    "some of our algorithms such as CNN's which use kernel filters \n",
    "preform well wioth images.\n",
    "\n",
    "2. Generating New Data\n",
    "The second step is to generate new data from the orignals.\n",
    "This new data will have randomized spacial translations \n",
    "(Affine trnaslations) applied to it. \n",
    "\n",
    "3. Filtering Data\n",
    "The third step is to filter the image data to make the model \n",
    "more robust. This is done by bluring the image and applying \n",
    "a canny edge detector to the image. This will remove noise and\n",
    "make the image more clear.\n",
    "\n",
    "4. Split Data\n",
    "The fourth step is to split the data into a training, and \n",
    "testing for the model. This is done by splitting the data\n",
    "into 80% training and 20% testing.\n",
    "\n",
    "Note: This file is not meant to be run once to prepare the data.\n",
    "we will train our model using the raw data and then use the\n",
    "images generated from the raw data to train our model and\n",
    "compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Formating Data to Images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Generating Images\n",
    "# class to generate new doodle images from a given images\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "class Image_Generator:\n",
    "    def __init__(self, src_image_path, gen_image_path, gen_image_name, num_images):\n",
    "        self.src_image_path = src_image_path\n",
    "        self.gen_image_path = gen_image_path\n",
    "        self.gen_image_name = gen_image_name\n",
    "        self.num_images = num_images\n",
    "\n",
    "    def affine_transform(self, image):\n",
    "        #generate new image using affine transformation\n",
    "        #return new image\n",
    "        image = img_to_array(image)\n",
    "        image = image.reshape((1,) + image.shape)\n",
    "        datagen = ImageDataGenerator(\n",
    "            rotation_range=40,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest')\n",
    "        i = 0\n",
    "        for batch in datagen.flow(image, batch_size=1, save_to_dir=self.gen_image_path, save_prefix=self.gen_image_name, save_format='npy'):\n",
    "            i += 1\n",
    "            if i > self.num_images:\n",
    "                break\n",
    "\n",
    "    def load_image(self):\n",
    "        #load image from curr_image_path\n",
    "        #return image\n",
    "        image = load_img(self.src_image_path)\n",
    "        return image\n",
    "\n",
    "    def generate_image(self):\n",
    "        #generate new images\n",
    "        image = self.load_image()\n",
    "        self.affine_transform(image)\n",
    "    \n",
    "    def generate_images(self):\n",
    "        #generate new images\n",
    "        for image in os.listdir(self.src_image_path):\n",
    "            image_path = os.path.join(self.src_image_path, image)\n",
    "            self.generate_image()\n",
    "\n",
    "#generate new images\n",
    "source = 'data/raw'\n",
    "destination = 'data/generated'\n",
    "name = 'gen_image'\n",
    "num_copies = 10\n",
    "\n",
    "image_generator = Image_Generator(source, destination, name, num_copies)\n",
    "image_generator.generate_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. filter images\n",
    "# class to filter images\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Image_Filter:\n",
    "    def __init__(self, image_path = None, destination_path = None):\n",
    "        self.image_path = image_path\n",
    "        self.destination_path = destination_path\n",
    "    \n",
    "    def set_image_path(self, source_path, destination_path):\n",
    "        #set image path\n",
    "        #return nothing\n",
    "        self.image_path = source_path\n",
    "        self.destination_path = destination_path\n",
    "\n",
    "    def filter_image(self):\n",
    "        #filter image\n",
    "        #return filtered image\n",
    "        image = cv2.imread(self.image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.GaussianBlur(image, (5,5), 0)\n",
    "        image = cv2.Canny(image, 50, 150)\n",
    "        return image\n",
    "\n",
    "    def filter_images(self):\n",
    "        #filter images\n",
    "        for image in os.listdir(self.image_path):\n",
    "            path = os.path.join(self.destination_path, image)\n",
    "            filtered_image = self.filter_image()\n",
    "            cv2.imwrite(path, filtered_image)\n",
    "\n",
    "#filter images\n",
    "raw_img_path = 'data/raw'\n",
    "gen_img_path = 'data/generated'\n",
    "destination = 'data/processed'\n",
    "image_filter = Image_Filter(raw_img_path, destination)\n",
    "image_filter.filter_images()\n",
    "image_filter.set_image_path(gen_img_path, destination)\n",
    "image_filter.filter_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Split Data\n",
    "# function to organize data into training and testing\n",
    "def split_Data(self, src_data_path, train_data_path, test_data_path):\n",
    "    #split data into 80% train, 20% test\n",
    "    #return None\n",
    "    for root, dirs, files in os.walk(src_data_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".npy\"):\n",
    "                img = cv2.imread(os.path.join(root, file), 0)\n",
    "                img = img.flatten()\n",
    "                if np.random.rand() < 0.8:\n",
    "                    cv2.imwrite(os.path.join(train_data_path, root.split(\"/\")[-1], file), img)\n",
    "                else:\n",
    "                    cv2.imwrite(os.path.join(test_data_path, root.split(\"/\")[-1], file), img)\n",
    "\n",
    "#split data\n",
    "source = 'data/preprocessed/processed'\n",
    "train = 'data/train'\n",
    "test = 'data/test'\n",
    "split_Data(source, train, test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4bc1b6540c1e5d4fc47617a1e73be04a796ca42dcf02d0e886ec9883aabc8f3c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
